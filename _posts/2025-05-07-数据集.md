---
layout:     post
title:     数据集
subtitle:   LLM
date:       2025-05-07
author:     SHK
header-img: img/post-bg-debug.png
catalog: true
tags: 
    - NLP
---

## SFT 监督微调 数据集格式

1. 输入数据：输入数据是一个文本序列，通常是一个句子或者一个段落。每个样本可以是一个字符串或者是一个tokenized的文本序列。
2. 标签数据：标签数据是与输入数据对应的标签或类别。标签可以是单个类别，也可以是多个类别的集合。对于多分类任务，通常使用**one-hot编码或整数编码来表示标签**。
3. 数据集划分：数据集通常需要划分为训练集、验证集和测试集。训练集用于模型的训练，验证集用于调整模型的超参数和监控模型的性能，测试集用于评估模型的最终性能。
4. 数据集格式：数据集可以以文本文件（如CSV、JSON等）或数据库的形式存储。每个样本包含输入数据和对应的标签。可以使用表格形式存储数据，每一列代表一个特征或标签。

```bash
Input,Label
"This is a sentence.",1
"Another sentence.",0
...
```

在这个示例中，**输入数据是一个句子，标签是一个二分类的标签**（1代表正例，0代表负例）。每一行代表一个样本，第一列是输入数据，第二列是对应的标签。

## Reward Model 数据格式

在大语言模型训练中，RM（Reward Model，奖励模型）的数据格式可以采用以下方式：

1. 输入数据：输入数据是一个文本序列，通常是一个句子或者一个段落。每个样本可以是一个字符串或者是一个tokenized的文本序列。
2. 奖励数据：奖励数据是与输入数据对应的奖励或评分。奖励可以是一个实数值，表示对输入数据的评价。也可以是一个离散的标签，表示对输入数据的分类。奖励数据可以是人工标注的，也可以是通过其他方式（如人工评估、强化学习等）得到的。
3. 数据集格式：数据集可以以文本文件（如CSV、JSON等）或数据库的形式存储。每个样本包含输入数据和对应的奖励数据。可以使用表格形式存储数据，每一列代表一个特征或标签。

```bash
Input,Reward
"This is a sentence.",0.8
"Another sentence.",0.2
...
```

## PPO数据格式

```bash
Input,Reward,Action,State
 "This is a sentence.",0.8,"This is a generated sentence.",[0.1, 0.2, 0.3, ...]
"Another sentence.",0.2,"Another generated sentence.",[0.4, 0.5, 0.6, ...]
...
```

## 微调需要多少条数据

根据 Scaling Laws，随着模型大小、数据集大小和用于训练的计算浮点数的增加，模型的性能会提高。并且为了获得最佳性能，所有三个因素**必须同时放大**。一般来说对于给定模型的理想训练数据集 token 数量大约是模型中参数数量的20倍。

## 数据集

以下是一些常用的大语言模型训练集的示例：

1. Common Crawl：这是一个由互联网上抓取的大规模文本数据集，包含了来自各种网站的文本内容。它是一个常用的数据集，可用于语言模型的训练。
2. Wikipedia：维基百科是一个包含大量结构化文本的在线百科全书。维基百科的内容丰富多样，涵盖了各种领域的知识，可以作为语言模型训练的数据集。
3. OpenWebText：这是一个从互联网上抓取的开放文本数据集，类似于Common Crawl。它包含了大量的网页文本，可以作为语言模型的训练数据。
4. BookCorpus：这是一个包含了大量图书文本的数据集，用于语言模型的训练。它包括了各种类型的图书，涵盖了广泛的主题和领域。
5. News articles：新闻文章是另一个常用的语言模型训练集。可以通过从新闻网站、新闻API或新闻数据库中收集新闻文章来构建训练集。
6. 其他领域特定数据集：根据具体任务和应用，可以使用特定领域的数据集来训练语言模型。例如，在医学领域，可以使用医学文献或医疗记录作为训练数据；在法律领域，可以使用法律文书或法律条款作为训练数据。

